{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 140\n",
    "\n",
    "import psytrack as psy\n",
    "import scipy.io\n",
    "\n",
    "mouseList = ['zz064']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running xval fold 5 of 5"
     ]
    }
   ],
   "source": [
    "for mouse in mouseList:\n",
    "    mat = scipy.io.loadmat('C:/Users/zzhu34/Documents/gitRep/octoBehavior/psyTrackData/' + mouse +'.mat',mat_dtype=True)\n",
    "    mat['y'] = mat['y'].flatten();mat['correct'] = mat['correct'].flatten();\n",
    "    mat['dayLength'] = mat['dayLength'].flatten();mat['answer'] = mat['answer'].flatten();\n",
    "    mat['inputs'] = {'stimulus': mat['stimulus'],'stimH': mat['stimH'], 'actionH': mat['actionH'],\n",
    "                     'actionXrewardH': mat['actionXrewardH'],'actionXrewardXcurrstimH':mat['actionXrewardXcurrstimH']}\n",
    "    del mat['stimulus'], mat['stimH'], mat['actionH'], mat['actionXrewardH'],mat['actionXrewardXcurrstimH']\n",
    "    \n",
    "    # STIMULUS ACTION REWARD MODEL\n",
    "    weights = {'bias': 0,  # a special key\n",
    "               'stimulus': 1, 'stimH': 0,    # use only the first column of s1 from inputs  \n",
    "               'actionH': 0, 'actionXrewardH': 1, 'actionXrewardXcurrstimH': 0 }    # use only the first column of s2 from inputs\n",
    "\n",
    "    # It is often useful to have the total number of weights K in your model\n",
    "    K = np.sum([weights[i] for i in weights.keys()]);\n",
    "\n",
    "    hyper= {'sigInit': 2**4.,      # Set to a single, large value for all weights. Will not be optimized further.\n",
    "            'sigma': [2**-4.]*K,   # Each weight will have it's own sigma optimized, but all are initialized the same\n",
    "            'sigDay': 2**-2.}        # Indicates that session boundaries will be ignored in the optimization\n",
    "    optList = ['sigma','sigDay']\n",
    "    hyp, evd, wMode, hess_info = psy.hyperOpt(mat, hyper, weights, optList)\n",
    "    xval_logli, xval_pL = psy.crossValidate(mat, hyper, weights, optList, F=5, seed=41)\n",
    "\n",
    "    scipy.io.savemat('C:/Users/zzhu34/Documents/gitRep/octoBehavior/psyTrackData/' + mouse + 'psytrack_SAr.mat',\n",
    "                     {'xval_logli':xval_logli, 'xval_pL':xval_pL, 'hyp':hyp, 'evd':evd, 'wMode':wMode, 'hess_info':hess_info,\n",
    "                     'hyper':hyper, 'optList':optList, 'weights':weights, 'K':K})\n",
    "    \n",
    "    \n",
    "    # STIMULUS ACTION REWARD STIM MODEL\n",
    "    weights = {'bias': 0,  # a special key\n",
    "               'stimulus': 1, 'stimH': 0,    # use only the first column of s1 from inputs  \n",
    "               'actionH': 0, 'actionXrewardH': 0, 'actionXrewardXcurrstimH': 1 }    # use only the first column of s2 from inputs\n",
    "\n",
    "    # It is often useful to have the total number of weights K in your model\n",
    "    K = np.sum([weights[i] for i in weights.keys()]);\n",
    "\n",
    "    hyper= {'sigInit': 2**4.,      # Set to a single, large value for all weights. Will not be optimized further.\n",
    "            'sigma': [2**-4.]*K,   # Each weight will have it's own sigma optimized, but all are initialized the same\n",
    "            'sigDay': 2**-2.}        # Indicates that session boundaries will be ignored in the optimization\n",
    "    optList = ['sigma','sigDay']\n",
    "    hyp, evd, wMode, hess_info = psy.hyperOpt(mat, hyper, weights, optList)\n",
    "    xval_logli, xval_pL = psy.crossValidate(mat, hyper, weights, optList, F=5, seed=41)\n",
    "\n",
    "    scipy.io.savemat('C:/Users/zzhu34/Documents/gitRep/octoBehavior/psyTrackData/' + mouse + 'psytrack_SArs.mat',\n",
    "                     {'xval_logli':xval_logli, 'xval_pL':xval_pL, 'hyp':hyp, 'evd':evd, 'wMode':wMode, 'hess_info':hess_info,\n",
    "                     'hyper':hyper, 'optList':optList, 'weights':weights, 'K':K})\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running xval fold 4 of 5"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Factor is exactly singular",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-294438a0a5b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0moptList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'sigma'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'sigDay'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mhyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwMode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhess_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpsy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperOpt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhyper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mxval_logli\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxval_pL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpsy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrossValidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhyper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m41\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     scipy.io.savemat('C:/Users/zzhu34/Documents/gitRep/octoBehavior/psyTrackData/' + mouse + 'psytrack_SB.mat',\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\psytrack\\helper\\crossValidation.py\u001b[0m in \u001b[0;36mcrossValidate\u001b[1;34m(D, hyper_guess, weight_dict, optList, F, seed, verbose)\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\rRunning xval fold \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" of \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         _, _, wMode, _ = hyperOpt(train_dats[f], hyper_guess, weight_dict,\n\u001b[1;32m---> 31\u001b[1;33m                                   optList, hess_calc=None)\n\u001b[0m\u001b[0;32m     32\u001b[0m         logli, gw = xval_loglike(test_dats[f], wMode,\n\u001b[0;32m     33\u001b[0m                                  train_dats[f]['missing_trials'], weight_dict)\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\psytrack\\hyperOpt.py\u001b[0m in \u001b[0;36mhyperOpt\u001b[1;34m(dat, hyper, weights, optList, method, showOpt, jump, hess_calc)\u001b[0m\n\u001b[0;32m    181\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'BFGS'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m             \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m             \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m         )\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_minimize_cg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'bfgs'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_minimize_bfgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'newton-cg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         return _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_minimize_bfgs\u001b[1;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, **unknown_options)\u001b[0m\n\u001b[0;32m    988\u001b[0m             \u001b[0malpha_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgfkp1\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m                      _line_search_wolfe12(f, myfprime, xk, pk, gfk,\n\u001b[1;32m--> 990\u001b[1;33m                                           old_fval, old_old_fval, amin=1e-100, amax=1e100)\n\u001b[0m\u001b[0;32m    991\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0m_LineSearchError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m             \u001b[1;31m# Line search failed to find a better solution.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_line_search_wolfe12\u001b[1;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, **kwargs)\u001b[0m\n\u001b[0;32m    808\u001b[0m     ret = line_search_wolfe1(f, fprime, xk, pk, gfk,\n\u001b[0;32m    809\u001b[0m                              \u001b[0mold_fval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m                              **kwargs)\n\u001b[0m\u001b[0;32m    811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mextra_condition\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py\u001b[0m in \u001b[0;36mline_search_wolfe1\u001b[1;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, args, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[0;32m     99\u001b[0m     stp, fval, old_fval = scalar_search_wolfe1(\n\u001b[0;32m    100\u001b[0m             \u001b[0mphi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mderphi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mderphi0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m             c1=c1, c2=c2, amax=amax, amin=amin, xtol=xtol)\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mstp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py\u001b[0m in \u001b[0;36mscalar_search_wolfe1\u001b[1;34m(phi, derphi, phi0, old_phi0, derphi0, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[0malpha1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m             \u001b[0mphi1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mphi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m             \u001b[0mderphi1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mderphi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py\u001b[0m in \u001b[0;36mderphi\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mderphi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         \u001b[0mgval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfprime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mnewargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[0mgc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[1;34m(*wrapper_args)\u001b[0m\n\u001b[0;32m    298\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36mapprox_fprime\u001b[1;34m(xk, f, epsilon, *args)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m     \"\"\"\n\u001b[1;32m--> 730\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    731\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_approx_fprime_helper\u001b[1;34m(xk, f, epsilon, args, f0)\u001b[0m\n\u001b[0;32m    668\u001b[0m         \u001b[0mei\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mei\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m         \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mf0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    671\u001b[0m         \u001b[0mei\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[1;34m(*wrapper_args)\u001b[0m\n\u001b[0;32m    298\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\psytrack\\hyperOpt.py\u001b[0m in \u001b[0;36mhyperOpt_lossfun\u001b[1;34m(optVals, keywords)\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[1;31m# Calculate posterior term, then approximate evidence for new sigma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[0mcenter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDL_2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ddlogli'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'H'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m     \u001b[0mlogterm_post\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msparse_logdet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcenter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[0mevd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'logprior'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'logli'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlogterm_post\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\psytrack\\helper\\helperFunctions.py\u001b[0m in \u001b[0;36msparse_logdet\u001b[1;34m(A)\u001b[0m\n\u001b[0;32m     47\u001b[0m             'sparse_logdet: matrix passed is not in sparse csc form')\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     return np.sum(\n\u001b[0;32m     51\u001b[0m         np.log(np.abs(aux.L.diagonal())) + np.log(np.abs(aux.U.diagonal())))\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\linalg\\dsolve\\linsolve.py\u001b[0m in \u001b[0;36msplu\u001b[1;34m(A, permc_spec, diag_pivot_thresh, relax, panel_size, options)\u001b[0m\n\u001b[0;32m    309\u001b[0m         \u001b[0m_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     return _superlu.gstrf(N, A.nnz, A.data, A.indices, A.indptr,\n\u001b[1;32m--> 311\u001b[1;33m                           ilu=False, options=_options)\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Factor is exactly singular"
     ]
    }
   ],
   "source": [
    "for mouse in mouseList:\n",
    "# STIMULUS ONLY MODEL\n",
    "    weights = {'bias': 0,  # a special key\n",
    "               'stimulus': 1, 'stimH': 0,    # use only the first column of s1 from inputs  \n",
    "               'actionH': 0, 'actionXrewardH': 0, 'actionXrewardXcurrstimH': 0 }    # use only the first column of s2 from inputs\n",
    "\n",
    "    # It is often useful to have the total number of weights K in your model\n",
    "    K = np.sum([weights[i] for i in weights.keys()]);\n",
    "\n",
    "    hyper= {'sigInit': 2**4.,      # Set to a single, large value for all weights. Will not be optimized further.\n",
    "            'sigma': [2**-4.]*K,   # Each weight will have it's own sigma optimized, but all are initialized the same\n",
    "            'sigDay': 2**-2.}        # Indicates that session boundaries will be ignored in the optimization\n",
    "    optList = ['sigma','sigDay']\n",
    "    hyp, evd, wMode, hess_info = psy.hyperOpt(mat, hyper, weights, optList)\n",
    "    xval_logli, xval_pL = psy.crossValidate(mat, hyper, weights, optList, F=5, seed=41)\n",
    "\n",
    "    scipy.io.savemat('C:/Users/zzhu34/Documents/gitRep/octoBehavior/psyTrackData/' + mouse + 'psytrack_S.mat',\n",
    "                     {'xval_logli':xval_logli, 'xval_pL':xval_pL, 'hyp':hyp, 'evd':evd, 'wMode':wMode, 'hess_info':hess_info,\n",
    "                     'hyper':hyper, 'optList':optList, 'weights':weights, 'K':K})\n",
    "    \n",
    "    \n",
    "    # STIMULUS AND BIAS MODEL\n",
    "    weights = {'bias': 1,  # a special key\n",
    "               'stimulus': 1, 'stimH': 0,    # use only the first column of s1 from inputs  \n",
    "               'actionH': 0, 'actionXrewardH': 0, 'actionXrewardXcurrstimH': 0 }    # use only the first column of s2 from inputs\n",
    "\n",
    "    # It is often useful to have the total number of weights K in your model\n",
    "    K = np.sum([weights[i] for i in weights.keys()]);\n",
    "\n",
    "    hyper= {'sigInit': 2**4.,      # Set to a single, large value for all weights. Will not be optimized further.\n",
    "            'sigma': [2**-4.]*K,   # Each weight will have it's own sigma optimized, but all are initialized the same\n",
    "            'sigDay': 2**-2.}        # Indicates that session boundaries will be ignored in the optimization\n",
    "    optList = ['sigma','sigDay']\n",
    "    hyp, evd, wMode, hess_info = psy.hyperOpt(mat, hyper, weights, optList)\n",
    "    xval_logli, xval_pL = psy.crossValidate(mat, hyper, weights, optList, F=5, seed=41)\n",
    "\n",
    "    scipy.io.savemat('C:/Users/zzhu34/Documents/gitRep/octoBehavior/psyTrackData/' + mouse + 'psytrack_SB.mat',\n",
    "                     {'xval_logli':xval_logli, 'xval_pL':xval_pL, 'hyp':hyp, 'evd':evd, 'wMode':wMode, 'hess_info':hess_info,\n",
    "                     'hyper':hyper, 'optList':optList, 'weights':weights, 'K':K})\n",
    "    \n",
    "    \n",
    "    # STIMULUS AND ACTIONH MODEL\n",
    "    weights = {'bias': 0,  # a special key\n",
    "               'stimulus': 1, 'stimH': 0,    # use only the first column of s1 from inputs  \n",
    "               'actionH': 1, 'actionXrewardH': 0, 'actionXrewardXcurrstimH': 0 }    # use only the first column of s2 from inputs\n",
    "\n",
    "    # It is often useful to have the total number of weights K in your model\n",
    "    K = np.sum([weights[i] for i in weights.keys()]);\n",
    "\n",
    "    hyper= {'sigInit': 2**4.,      # Set to a single, large value for all weights. Will not be optimized further.\n",
    "            'sigma': [2**-4.]*K,   # Each weight will have it's own sigma optimized, but all are initialized the same\n",
    "            'sigDay': 2**-2.}        # Indicates that session boundaries will be ignored in the optimization\n",
    "    optList = ['sigma','sigDay']\n",
    "    hyp, evd, wMode, hess_info = psy.hyperOpt(mat, hyper, weights, optList)\n",
    "    xval_logli, xval_pL = psy.crossValidate(mat, hyper, weights, optList, F=5, seed=41)\n",
    "\n",
    "    scipy.io.savemat('C:/Users/zzhu34/Documents/gitRep/octoBehavior/psyTrackData/' + mouse + 'psytrack_SA.mat',\n",
    "                     {'xval_logli':xval_logli, 'xval_pL':xval_pL, 'hyp':hyp, 'evd':evd, 'wMode':wMode, 'hess_info':hess_info,\n",
    "                     'hyper':hyper, 'optList':optList, 'weights':weights, 'K':K})\n",
    "    \n",
    "    \n",
    "    \n",
    "    # STIMULUS AND BIAS AND ACTIONH MODEL\n",
    "    weights = {'bias': 1,  # a special key\n",
    "               'stimulus': 1, 'stimH': 0,    # use only the first column of s1 from inputs  \n",
    "               'actionH': 1, 'actionXrewardH': 0, 'actionXrewardXcurrstimH': 0 }    # use only the first column of s2 from inputs\n",
    "\n",
    "    # It is often useful to have the total number of weights K in your model\n",
    "    K = np.sum([weights[i] for i in weights.keys()]);\n",
    "\n",
    "    hyper= {'sigInit': 2**4.,      # Set to a single, large value for all weights. Will not be optimized further.\n",
    "            'sigma': [2**-4.]*K,   # Each weight will have it's own sigma optimized, but all are initialized the same\n",
    "            'sigDay': 2**-2.}        # Indicates that session boundaries will be ignored in the optimization\n",
    "    optList = ['sigma','sigDay']\n",
    "    hyp, evd, wMode, hess_info = psy.hyperOpt(mat, hyper, weights, optList)\n",
    "    xval_logli, xval_pL = psy.crossValidate(mat, hyper, weights, optList, F=5, seed=41)\n",
    "\n",
    "    scipy.io.savemat('C:/Users/zzhu34/Documents/gitRep/octoBehavior/psyTrackData/' + mouse + 'psytrack_SBA.mat',\n",
    "                     {'xval_logli':xval_logli, 'xval_pL':xval_pL, 'hyp':hyp, 'evd':evd, 'wMode':wMode, 'hess_info':hess_info,\n",
    "                     'hyper':hyper, 'optList':optList, 'weights':weights, 'K':K})\n",
    "    \n",
    "    \n",
    "    \n",
    "    # STIMULUS AND BIAS AND ACTIONH AND ACTION X REWARD MODEL\n",
    "    weights = {'bias': 1,  # a special key\n",
    "               'stimulus': 1, 'stimH': 0,    # use only the first column of s1 from inputs  \n",
    "               'actionH': 1, 'actionXrewardH': 1, 'actionXrewardXcurrstimH': 0 }    # use only the first column of s2 from inputs\n",
    "\n",
    "    # It is often useful to have the total number of weights K in your model\n",
    "    K = np.sum([weights[i] for i in weights.keys()]);\n",
    "\n",
    "    hyper= {'sigInit': 2**4.,      # Set to a single, large value for all weights. Will not be optimized further.\n",
    "            'sigma': [2**-4.]*K,   # Each weight will have it's own sigma optimized, but all are initialized the same\n",
    "            'sigDay': 2**-2.}        # Indicates that session boundaries will be ignored in the optimization\n",
    "    optList = ['sigma','sigDay']\n",
    "    hyp, evd, wMode, hess_info = psy.hyperOpt(mat, hyper, weights, optList)\n",
    "    xval_logli, xval_pL = psy.crossValidate(mat, hyper, weights, optList, F=5, seed=41)\n",
    "\n",
    "    scipy.io.savemat('C:/Users/zzhu34/Documents/gitRep/octoBehavior/psyTrackData/' + mouse + 'psytrack_SBAAr.mat',\n",
    "                     {'xval_logli':xval_logli, 'xval_pL':xval_pL, 'hyp':hyp, 'evd':evd, 'wMode':wMode, 'hess_info':hess_info,\n",
    "                     'hyper':hyper, 'optList':optList, 'weights':weights, 'K':K})\n",
    "    \n",
    "    \n",
    "    \n",
    "    # STIMULUS AND BIAS AND ACTIONH AND ACTION X REWARD MODEL\n",
    "    weights = {'bias': 1,  # a special key\n",
    "               'stimulus': 1, 'stimH': 0,    # use only the first column of s1 from inputs  \n",
    "               'actionH': 1, 'actionXrewardH': 1, 'actionXrewardXcurrstimH': 1 }    # use only the first column of s2 from inputs\n",
    "\n",
    "    # It is often useful to have the total number of weights K in your model\n",
    "    K = np.sum([weights[i] for i in weights.keys()]);\n",
    "\n",
    "    hyper= {'sigInit': 2**4.,      # Set to a single, large value for all weights. Will not be optimized further.\n",
    "            'sigma': [2**-4.]*K,   # Each weight will have it's own sigma optimized, but all are initialized the same\n",
    "            'sigDay': 2**-2.}        # Indicates that session boundaries will be ignored in the optimization\n",
    "    optList = ['sigma','sigDay']\n",
    "    hyp, evd, wMode, hess_info = psy.hyperOpt(mat, hyper, weights, optList)\n",
    "    xval_logli, xval_pL = psy.crossValidate(mat, hyper, weights, optList, F=5, seed=41)\n",
    "\n",
    "    scipy.io.savemat('C:/Users/zzhu34/Documents/gitRep/octoBehavior/psyTrackData/' + mouse + 'psytrack_SBAArArs.mat',\n",
    "                     {'xval_logli':xval_logli, 'xval_pL':xval_pL, 'hyp':hyp, 'evd':evd, 'wMode':wMode, 'hess_info':hess_info,\n",
    "                     'hyper':hyper, 'optList':optList, 'weights':weights, 'K':K})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
